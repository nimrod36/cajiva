name: Generate Test Plan for Issue

on:
  issues:
    types: [opened]

jobs:
  generate-test-plan:
    runs-on: ubuntu-latest
    permissions:
      issues: write
      contents: read
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Generate Test Plan
        id: generate
        run: |
          ISSUE_TITLE="${{ github.event.issue.title }}"
          ISSUE_BODY="${{ github.event.issue.body }}"
          ISSUE_NUMBER="${{ github.event.issue.number }}"
          
          # Detect issue type from title and body
          ISSUE_TYPE="feature"
          if echo "$ISSUE_TITLE $ISSUE_BODY" | grep -qi "bug\|error\|crash\|fail\|broken\|fix"; then
            ISSUE_TYPE="bug"
          elif echo "$ISSUE_TITLE $ISSUE_BODY" | grep -qi "performance\|slow\|optimize\|speed"; then
            ISSUE_TYPE="performance"
          elif echo "$ISSUE_TITLE $ISSUE_BODY" | grep -qi "ui\|ux\|interface\|design\|layout"; then
            ISSUE_TYPE="ui"
          fi
          
          # Generate dynamic test plan based on issue type
          case $ISSUE_TYPE in
            bug)
              cat > test_plan.md << 'EOF'
          ## ðŸ› Bug Fix Test Plan - Issue #$ISSUE_NUMBER
          
          **Issue:** $ISSUE_TITLE
          
          ### Test Objectives
          - Reproduce the bug described in the issue
          - Verify the fix resolves the problem
          - Ensure no regressions are introduced
          
          ### Test Cases
          
          #### TC1: Reproduce Original Bug
          - **Steps:** Follow reproduction steps from issue
          - **Expected:** Bug is confirmed reproducible before fix
          - **Priority:** Critical
          
          #### TC2: Verify Bug Fix
          - **Steps:** Apply fix and retest reproduction steps
          - **Expected:** Bug no longer occurs
          - **Priority:** Critical
          
          #### TC3: Regression Testing
          - **Steps:** Test related functionality
          - **Expected:** No new issues introduced
          - **Priority:** High
          
          #### TC4: Edge Cases
          - **Steps:** Test boundary conditions related to the bug
          - **Expected:** Fix works in all scenarios
          - **Priority:** Medium
          
          ### Acceptance Criteria
          - [ ] Bug is reproducible before fix
          - [ ] Bug is resolved after fix
          - [ ] No regression in related features
          - [ ] Unit/integration tests added
          
          ---
          *Auto-generated bug fix test plan. Detected keywords: bug, error, fix*
          EOF
              ;;
              
            performance)
              cat > test_plan.md << 'EOF'
          ## âš¡ Performance Test Plan - Issue #$ISSUE_NUMBER
          
          **Issue:** $ISSUE_TITLE
          
          ### Test Objectives
          - Measure baseline performance
          - Verify performance improvements
          - Ensure no functionality regression
          
          ### Test Cases
          
          #### TC1: Baseline Measurement
          - **Steps:** Measure current performance metrics
          - **Expected:** Documented baseline values
          - **Priority:** High
          
          #### TC2: Performance Improvement
          - **Steps:** Apply optimization and remeasure
          - **Expected:** Measurable improvement in target metrics
          - **Priority:** Critical
          
          #### TC3: Load Testing
          - **Steps:** Test under various load conditions
          - **Expected:** Consistent performance across loads
          - **Priority:** Medium
          
          #### TC4: Resource Usage
          - **Steps:** Monitor CPU, memory, network usage
          - **Expected:** Resource usage within acceptable limits
          - **Priority:** Medium
          
          ### Acceptance Criteria
          - [ ] Performance improvement quantified
          - [ ] No functionality regression
          - [ ] Resource usage acceptable
          - [ ] Benchmarks documented
          
          ---
          *Auto-generated performance test plan. Detected keywords: performance, optimize*
          EOF
              ;;
              
            ui)
              cat > test_plan.md << 'EOF'
          ## ðŸŽ¨ UI/UX Test Plan - Issue #$ISSUE_NUMBER
          
          **Issue:** $ISSUE_TITLE
          
          ### Test Objectives
          - Verify visual design matches requirements
          - Test user interactions and workflows
          - Ensure responsive design works
          
          ### Test Cases
          
          #### TC1: Visual Design
          - **Steps:** Compare implementation with design specs
          - **Expected:** Visual elements match requirements
          - **Priority:** High
          
          #### TC2: User Interactions
          - **Steps:** Test all interactive elements
          - **Expected:** All interactions work smoothly
          - **Priority:** Critical
          
          #### TC3: Responsive Design
          - **Steps:** Test on mobile, tablet, desktop
          - **Expected:** Layout adapts properly to all screen sizes
          - **Priority:** High
          
          #### TC4: Accessibility
          - **Steps:** Test with screen readers, keyboard navigation
          - **Expected:** UI is accessible to all users
          - **Priority:** Medium
          
          ### Acceptance Criteria
          - [ ] Visual design approved
          - [ ] All interactions working
          - [ ] Responsive on all devices
          - [ ] Accessibility standards met
          
          ---
          *Auto-generated UI/UX test plan. Detected keywords: ui, ux, interface*
          EOF
              ;;
              
            *)
              cat > test_plan.md << 'EOF'
          ## âœ¨ Feature Test Plan - Issue #$ISSUE_NUMBER
          
          **Issue:** $ISSUE_TITLE
          
          ### Test Objectives
          - Verify feature requirements are met
          - Validate integration with existing code
          - Ensure quality and maintainability
          
          ### Test Cases
          
          #### TC1: Core Functionality
          - **Steps:** Test main feature implementation
          - **Expected:** Feature works as described in issue
          - **Priority:** Critical
          
          #### TC2: Integration
          - **Steps:** Test feature with existing functionality
          - **Expected:** Seamless integration, no conflicts
          - **Priority:** High
          
          #### TC3: Edge Cases
          - **Steps:** Test boundary conditions and unusual inputs
          - **Expected:** Feature handles edge cases gracefully
          - **Priority:** Medium
          
          #### TC4: Error Handling
          - **Steps:** Test with invalid inputs and error conditions
          - **Expected:** Appropriate error messages displayed
          - **Priority:** Medium
          
          ### Acceptance Criteria
          - [ ] All requirements from issue implemented
          - [ ] Tests pass (unit + integration)
          - [ ] Code reviewed and approved
          - [ ] Documentation updated
          
          ---
          *Auto-generated feature test plan*
          EOF
              ;;
          esac
          
          # Replace variables in the test plan
          sed -i "s/\$ISSUE_NUMBER/$ISSUE_NUMBER/g" test_plan.md
          sed -i "s/\$ISSUE_TITLE/$ISSUE_TITLE/g" test_plan.md
          
          # Save test plan content for next step
          echo "test_plan_content<<EOF" >> $GITHUB_OUTPUT
          cat test_plan.md >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
      
      - name: Comment Test Plan on Issue
        uses: actions/github-script@v7
        with:
          script: |
            const testPlan = `${{ steps.generate.outputs.test_plan_content }}`;
            
            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: testPlan
            });
            
            // Add label
            await github.rest.issues.addLabels({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              labels: ['test-plan-generated']
            });
